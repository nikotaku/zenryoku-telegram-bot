"""
ã‚­ãƒ£ã‚¹ã‚«ãƒ³ (caskan.jp) ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ â€” ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ™ãƒ¼ã‚¹ã®æƒ…å ±å–å¾—
"""

import os
import re
import logging
import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta, date as date_type
import calendar

logger = logging.getLogger(__name__)

CASKAN_SHOP_ID = os.environ.get("CASKAN_SHOP_ID", "Zenryoku1209")
CASKAN_LOGIN_ID = os.environ.get("CASKAN_LOGIN_ID", "zr.sendai@gmail.com")
CASKAN_PASSWORD = os.environ.get("CASKAN_PASSWORD", "Zenryoku1209")

BASE_URL = "https://my.caskan.jp"


class CaskanClient:
    """ã‚­ãƒ£ã‚¹ã‚«ãƒ³ç®¡ç†ç”»é¢ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""

    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        })
        self._logged_in = False

    def login(self) -> bool:
        """ã‚­ãƒ£ã‚¹ã‚«ãƒ³ã«ãƒ­ã‚°ã‚¤ãƒ³ï¼ˆ2æ®µéšãƒ•ã‚©ãƒ¼ãƒ ï¼‰"""
        try:
            # Step 1: åº—èˆ—IDã¨ãƒ­ã‚°ã‚¤ãƒ³IDã‚’é€ä¿¡
            resp = self.session.post(
                f"{BASE_URL}/login",
                data={
                    "mode": "step1",
                    "shop_code": CASKAN_SHOP_ID,
                    "code": CASKAN_LOGIN_ID,
                },
                timeout=15,
                allow_redirects=True,
            )

            if resp.status_code != 200:
                logger.error(f"Step1å¤±æ•—: {resp.status_code}")
                return False

            # Step 2: ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’é€ä¿¡
            resp2 = self.session.post(
                f"{BASE_URL}/login/password",
                data={
                    "mode": "step2",
                    "login_password": CASKAN_PASSWORD,
                },
                timeout=15,
                allow_redirects=True,
            )

            if "/login" not in resp2.url:
                self._logged_in = True
                logger.info("ã‚­ãƒ£ã‚¹ã‚«ãƒ³ã«ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ")
                return True
            else:
                logger.error("ã‚­ãƒ£ã‚¹ã‚«ãƒ³ãƒ­ã‚°ã‚¤ãƒ³å¤±æ•—ï¼ˆãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ä¸æ­£ï¼‰")
                return False

        except Exception as e:
            logger.error(f"ã‚­ãƒ£ã‚¹ã‚«ãƒ³ãƒ­ã‚°ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def _ensure_login(self) -> bool:
        if not self._logged_in:
            return self.login()
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ‡ã‚Œãƒã‚§ãƒƒã‚¯
        try:
            resp = self.session.get(f"{BASE_URL}/", timeout=10, allow_redirects=False)
            if resp.status_code in (301, 302) and "/login" in resp.headers.get("Location", ""):
                self._logged_in = False
                return self.login()
        except Exception:
            pass
        return True

    def get_home_info(self) -> dict:
        """ãƒ›ãƒ¼ãƒ ç”»é¢ã‹ã‚‰å£²ä¸Šæƒ…å ±ã¨å‡ºå‹¤æƒ…å ±ã‚’å–å¾—"""
        if not self._ensure_login():
            return {"error": "ãƒ­ã‚°ã‚¤ãƒ³ã«å¤±æ•—ã—ã¾ã—ãŸ"}

        try:
            resp = self.session.get(f"{BASE_URL}/", timeout=15)
            soup = BeautifulSoup(resp.text, "html.parser")

            result = {
                "sales": {},
                "attendance_text": "",
                "guidance_text": "",
            }

            # ãƒ†ã‚­ã‚¹ãƒˆå…¨ä½“ã‚’å–å¾—
            text = soup.get_text(separator="\n", strip=True)
            lines = text.split("\n")

            # å£²ä¸Šæƒ…å ±ã‚’æŠ½å‡ºï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ï¼‰
            for i, line in enumerate(lines):
                line_s = line.strip()
                if line_s == "æœ¬æ—¥" and i + 1 < len(lines):
                    result["sales"]["today"] = lines[i + 1].strip()
                elif line_s == "æ˜¨æ—¥" and i + 1 < len(lines):
                    result["sales"]["yesterday"] = lines[i + 1].strip()
                elif line_s == "ä»Šæœˆ" and i + 1 < len(lines):
                    result["sales"]["this_month"] = lines[i + 1].strip()
                elif line_s == "æ˜¨æœˆ" and i + 1 < len(lines):
                    result["sales"]["last_month"] = lines[i + 1].strip()

            # textarea ã‹ã‚‰å‡ºå‹¤æƒ…å ±ã‚’å–å¾—
            textareas = soup.find_all("textarea")
            for ta in textareas:
                content = ta.get_text(strip=True)
                if "å‡ºå‹¤æƒ…å ±" in content:
                    result["attendance_text"] = content
                elif "æ¡ˆå†…çŠ¶æ³" in content:
                    result["guidance_text"] = content

            return result

        except Exception as e:
            logger.error(f"ãƒ›ãƒ¼ãƒ æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    def get_schedule(self) -> dict:
        """é€±é–“ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å–å¾—"""
        if not self._ensure_login():
            return {"error": "ãƒ­ã‚°ã‚¤ãƒ³ã«å¤±æ•—ã—ã¾ã—ãŸ"}

        try:
            resp = self.session.get(f"{BASE_URL}/schedule/week", timeout=15)
            soup = BeautifulSoup(resp.text, "html.parser")

            text = soup.get_text(separator="\n", strip=True)

            # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æƒ…å ±ã‚’æ§‹é€ åŒ–ã—ã¦æŠ½å‡º
            schedule_lines = []
            lines = text.split("\n")
            current_date = ""

            for line in lines:
                line = line.strip()
                if not line:
                    continue

                # æ—¥ä»˜ãƒ‘ã‚¿ãƒ¼ãƒ³ (ä¾‹: 2/24 (ç«))
                date_match = re.match(r"(\d+/\d+\s*\([æœˆç«æ°´æœ¨é‡‘åœŸæ—¥]\))", line)
                if date_match:
                    current_date = date_match.group(1)
                    schedule_lines.append(f"\nğŸ“… {current_date}")
                    continue

                # ãƒ«ãƒ¼ãƒ æƒ…å ±
                if "room" in line.lower():
                    schedule_lines.append(f"  ğŸ  {line}")
                    continue

                # æ™‚é–“å¸¯ãƒ‘ã‚¿ãƒ¼ãƒ³ (ä¾‹: 13:00ã€œ25:00)
                time_match = re.search(r"\d{1,2}:\d{2}[ã€œ~-]\d{1,2}:\d{2}", line)
                if time_match and current_date:
                    schedule_lines.append(f"  â° {line}")
                    continue

                # ã‚»ãƒ©ãƒ”ã‚¹ãƒˆåï¼ˆçŸ­ã„æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆï¼‰
                if current_date and len(line) < 15 and re.match(r"^[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF]+$", line):
                    schedule_lines.append(f"  ğŸ‘¤ {line}")

            return {
                "schedule_text": "\n".join(schedule_lines) if schedule_lines else "ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“",
            }

        except Exception as e:
            logger.error(f"ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    def get_reservations(self) -> dict:
        """äºˆç´„ä¸€è¦§ã‚’å–å¾—"""
        if not self._ensure_login():
            return {"error": "ãƒ­ã‚°ã‚¤ãƒ³ã«å¤±æ•—ã—ã¾ã—ãŸ"}

        try:
            resp = self.session.get(f"{BASE_URL}/reservation", timeout=15)
            soup = BeautifulSoup(resp.text, "html.parser")

            reservations = []
            tables = soup.find_all("table")
            for table in tables:
                rows = table.find_all("tr")
                for row in rows:
                    cells = row.find_all(["td", "th"])
                    if cells:
                        row_text = " | ".join(c.get_text(strip=True) for c in cells)
                        if row_text.strip():
                            reservations.append(row_text)

            return {
                "reservations": reservations[:20],
                "count": len(reservations),
            }

        except Exception as e:
            logger.error(f"äºˆç´„å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    def get_room_map(self) -> dict:
        """ãƒ«ãƒ¼ãƒ IDã¨ãƒ«ãƒ¼ãƒ åã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’å–å¾—"""
        if not self._ensure_login():
            return {}
        try:
            resp = self.session.get(f"{BASE_URL}/room", timeout=15)
            soup = BeautifulSoup(resp.text, "html.parser")
            room_map = {}
            inputs = soup.find_all("input", {"name": re.compile(r"^sort\[")})
            for inp in inputs:
                room_id = inp.get("value", "")
                tr = inp.find_parent("tr")
                if tr:
                    link = tr.find("a", href=re.compile(r"/room/view"))
                    if link:
                        room_name = link.get_text(separator=" ", strip=True).split()[0]
                        room_map[room_id] = room_name
            return room_map
        except Exception as e:
            logger.error(f"ãƒ«ãƒ¼ãƒ ãƒãƒƒãƒ—å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    def get_monthly_shift(self, year: int, month: int) -> dict:
        """
        æŒ‡å®šæœˆã®ã‚·ãƒ•ãƒˆæƒ…å ±ã¨ãƒ«ãƒ¼ãƒ ç©ºãçŠ¶æ³ã‚’å–å¾—ã—ã¦æœˆã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼å½¢å¼ã§è¿”ã™ã€‚

        Returns:
            {
                'year': int,
                'month': int,
                'room_map': {room_id: room_name},
                'days': {
                    'YYYY-MM-DD': {
                        'weekday': 'æœˆ',
                        'shifts': [
                            {'name': str, 'time': str, 'room_id': str, 'room_name': str}
                        ],
                        'rooms_used': [room_id, ...],
                    }
                }
            }
        """
        if not self._ensure_login():
            return {"error": "ãƒ­ã‚°ã‚¤ãƒ³ã«å¤±æ•—ã—ã¾ã—ãŸ"}

        try:
            room_map = self.get_room_map()
            # æœˆã®æœ€åˆã®æ—¥ã¨æœ€å¾Œã®æ—¥ã‚’è¨ˆç®—
            first_day = date_type(year, month, 1)
            last_day = date_type(year, month, calendar.monthrange(year, month)[1])

            # é€±ã”ã¨ã«ã‚·ãƒ•ãƒˆè¡¨ã‚’å–å¾—ï¼ˆ7æ—¥å˜ä½ï¼‰
            all_shifts: dict = {}  # date_str -> list of shifts
            current = first_day
            fetched_weeks = set()

            while current <= last_day:
                week_key = current.strftime("%Y-%m-%d")
                if week_key not in fetched_weeks:
                    fetched_weeks.add(week_key)
                    resp = self.session.get(
                        f"{BASE_URL}/shift/view?start_day={week_key}",
                        timeout=15,
                    )
                    soup = BeautifulSoup(resp.text, "html.parser")

                    # parts-cast-table ã‹ã‚‰ã‚·ãƒ•ãƒˆæƒ…å ±ã‚’æŠ½å‡º
                    cast_tables = soup.find_all("table", class_="parts-cast-table")
                    for ct in cast_tables:
                        for row in ct.find_all("tr"):
                            td = row.find("td")
                            if not td:
                                continue
                            divs = td.find_all("div")
                            name = divs[0].get_text(strip=True) if divs else ""
                            time_str = divs[1].get_text(strip=True) if len(divs) > 1 else ""
                            edit_span = td.find("span", {"data-room-id": True})
                            if not edit_span:
                                continue
                            room_id = edit_span.get("data-room-id", "")
                            day_str = edit_span.get("data-day", "")
                            if not day_str or not name:
                                continue
                            # å¯¾è±¡æœˆã®ã¿è¨˜éŒ²
                            try:
                                d = datetime.strptime(day_str, "%Y-%m-%d").date()
                            except ValueError:
                                continue
                            if d.year == year and d.month == month:
                                if day_str not in all_shifts:
                                    all_shifts[day_str] = []
                                all_shifts[day_str].append({
                                    "name": name,
                                    "time": time_str,
                                    "room_id": room_id,
                                    "room_name": room_map.get(room_id, f"Room{room_id}"),
                                })
                current += timedelta(days=7)

            # æœˆã®å…¨æ—¥ä»˜ã‚’åŸ‹ã‚ã‚‹
            weekday_names = ["æœˆ", "ç«", "æ°´", "æœ¨", "é‡‘", "åœŸ", "æ—¥"]
            days = {}
            d = first_day
            while d <= last_day:
                day_str = d.strftime("%Y-%m-%d")
                shifts = all_shifts.get(day_str, [])
                rooms_used = list({s["room_id"] for s in shifts})
                days[day_str] = {
                    "weekday": weekday_names[d.weekday()],
                    "shifts": shifts,
                    "rooms_used": rooms_used,
                }
                d += timedelta(days=1)

            return {
                "year": year,
                "month": month,
                "room_map": room_map,
                "days": days,
            }

        except Exception as e:
            logger.error(f"æœˆã‚·ãƒ•ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    def get_cast_list(self) -> list:
        """ã‚­ãƒ£ã‚¹ãƒˆä¸€è¦§ã‚’å–å¾—"""
        if not self._ensure_login():
            return []

        try:
            resp = self.session.get(f"{BASE_URL}/cast", timeout=15)
            soup = BeautifulSoup(resp.text, "html.parser")

            casts = []
            seen = set()

            # ãƒ†ãƒ¼ãƒ–ãƒ«ã®è¡Œã‹ã‚‰ã‚­ãƒ£ã‚¹ãƒˆæƒ…å ±ã‚’æŠ½å‡º
            rows = soup.find_all("tr")
            for row in rows:
                # åå‰ãƒªãƒ³ã‚¯ã‚’æ¢ã™
                links = row.find_all("a")
                for link in links:
                    href = link.get("href", "")
                    text = link.get_text(strip=True)
                    if "/cast/" in href and text and "ç·¨é›†" not in text and text not in seen:
                        # è¿½åŠ æƒ…å ±ã‚’è¡Œã‹ã‚‰å–å¾—
                        row_text = row.get_text(separator=" ", strip=True)
                        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ç¢ºèª
                        status = "æ²è¼‰ä¸­" if "æ²è¼‰ä¸­" in row_text else "æœªæ²è¼‰"
                        casts.append(f"{text} [{status}]")
                        seen.add(text)

            return casts

        except Exception as e:
            logger.error(f"ã‚­ãƒ£ã‚¹ãƒˆä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []
